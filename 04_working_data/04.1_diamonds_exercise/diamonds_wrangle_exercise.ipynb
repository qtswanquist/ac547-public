{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Export, Import, Clean, Merge Tutorial\n",
    "\n",
    "The purpose of this exercise is to illustrate several wrangling concepts covered in class and in DataCamp. We begin by “messing up” the diamonds data then put it back together. During this exercise, you will see imports, exports, reshapes, joins, mutations, and more!\n",
    "\n",
    "Note: This notebook is intended to be interactive and contains incomplete code. See [solution file](diamonds_wrangle_exercise_solution.ipynb) in this repository for the final solution and output.\n",
    "\n",
    "## Housekeeping"
   ],
   "id": "64ffa8d71d648915"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "5d9d35e91861e783",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Deconstruct the diamonds dataset\n",
    "Open and store the diamonds dataset after applying a filter on carat weight (less than 1.5 carats) and keeping only carat, clarity, and price. Also, let's create a unique identifier (`uniq_id`) for each diamond. Information about the original dataset can be found [here](https://ggplot2.tidyverse.org/reference/diamonds.html). Store in a new dataset called `diamonds_subset`. This will be our starting point for the exercise."
   ],
   "id": "2f3c6fae47c68d65"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "diamonds = sns.load_dataset(\"diamonds\")\n",
    "# diamonds = pd.read_pickle('diamonds.pkl')\n",
    "\n",
    "diamonds_subset = (\n",
    "    diamonds[diamonds['carat'] < 1.5][['carat', 'clarity', 'price']]\n",
    "    .assign(uniq_id=lambda d: range(1, len(d) + 1)) # add a unique identifier\n",
    "    .reset_index(drop=True)\n",
    ")"
   ],
   "id": "d2274a92e47e4ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Take a look at a sample of the data:",
   "id": "eabe78372cb18abc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "diamonds_subset.sample(10, random_state=42)",
   "id": "9dea8359ef082441",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Select the `uniq_id` and `price` variables, rename the `uniq_id` as `id`, and add extra characters to `price`. Create a new dataset called `diamonds_prices`:",
   "id": "e7d765640fdca3c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "diamonds_prices = (\n",
    "    diamonds_subset[['uniq_id', 'price']]\n",
    "    .rename(columns={'uniq_id': 'id'})\n",
    ")\n",
    "\n",
    "diamonds_prices['price'] = 'amount ' + diamonds_prices['price'].astype(str) + ' USD'"
   ],
   "id": "d105c69cc2e619f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Add a few duplicated observations to `diamonds_prices` using a random draw from `diamonds_prices`:",
   "id": "5debd8c2c09de6cc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sampled = diamonds_prices.sample(55, random_state=42) # Take a random sample of 55 rows\n",
    "\n",
    "diamonds_prices = (\n",
    "    pd.concat([diamonds_prices, sampled]) # Append the sampled rows to the original diamonds_prices dataframe\n",
    "    .sort_values('id')\n",
    ")\n",
    "\n",
    "del sampled"
   ],
   "id": "1f8b1c2dd0c13cb1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Next, let's store the other diamond characteristics (i.e., carat and clarity) in another 'messy' dataset. Select the diamond characteristics excluding `price` and reshape to long format. Store as a new dataset - `diamonds_char_long`:",
   "id": "5afce3fa3d647207"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "diamonds_char = (\n",
    "    diamonds_subset\n",
    "    .drop(columns='price')\n",
    "    .melt(id_vars='uniq_id', var_name='variable', value_name='measure')\n",
    "    .sort_values(['uniq_id', 'variable'])\n",
    ")"
   ],
   "id": "9725a83e3ff25dc5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Save each of the new datasets in different formats (csv and txt) and delete all variables/data from the workspace:",
   "id": "ecad3b65873a63a0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "diamonds_prices.to_csv('diamonds_prices.csv', index=False)\n",
    "diamonds_char.to_csv('diamonds_char.txt', sep='\\t', index=False)\n",
    "\n",
    "del diamonds, diamonds_subset, diamonds_prices, diamonds_char"
   ],
   "id": "bbc6b023586d9f36",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Reconstruct the diamonds dataset\n",
    "Take a look at your working directory (i.e., the current folder we are working in). You should have two files saved from above. These files include all of the information from the original dataset (`diamonds_subset`), but the data is now in raw and messy form ☹️. Let's imagine that we are starting from scratch with only these files and need to reconstruct the diamonds dataset. Before we begin, find the files on your local computer and open them. To navigate to the file location, right-click on the file/folder and select 'open in' then select explorer (or finder on a Mac).\n",
    "\n",
    "Let’s begin by importing each dataset as `diamonds_prices_import` and `diamonds_char_import`:"
   ],
   "id": "f11629905178fdc9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "diamonds_prices_import =\n",
    "diamonds_char_import ="
   ],
   "id": "a90a8840d156f821",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Take a look at a sample of the `diamonds_prices` data.",
   "id": "e8f34c3d4dad2dc5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "71a038d00a52db7d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As you can see, the price variable needs to be cleaned. We need to remove the text and keep only the price. Let’s tackle it!",
   "id": "c8c7e0a6ac6fc984"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Copy diamonds_prices_import in diamonds_prices for cleaning\n",
    "diamonds_prices = diamonds_prices_import.copy()\n",
    "\n",
    "# Remove \"amount \" from the price column\n",
    "\n",
    "# Split the price column into two columns: the price and currency\n",
    "\n",
    "# Convert the numeric price (currently a string) into numeric type\n",
    "\n",
    "\n",
    "diamonds_prices.sample(10, random_state=42)"
   ],
   "id": "17ea56c715a55dbc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Recall that we added some duplicates to the prices dataset… let’s check for duplicates and store in a variable called `duplicates`.",
   "id": "4844934a0871a2ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "duplicates =\n",
    "\n",
    "duplicates.head()"
   ],
   "id": "28c1c702ad3ffd5c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This reports the duplicated observations in the dataset. Take a look at the `duplicates` dataframe. There are 110 rows and 55 duplicated observations. A quick inspection suggests that the duplicates are exact copies of each other. We can remove the duplicates by keeping only the first occurrence of each duplicated `id`.",
   "id": "a393f0217446ee92"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "diamonds_prices =",
   "id": "8c94ea8a6a438161",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Next, we need to work with the diamonds_char_import dataset. Let's start by inspecting the dataset:",
   "id": "8463e6cb6cf7df8d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "diamonds_char_import.head(8)",
   "id": "3c20a2f3e4ff0349",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "At first glance, this dataset seems to have many duplicate values for `uniq_id`. However, a closer look suggests that each row contains different information about each diamond. Remember what we learned about *tidy data*... Each observation (i.e., diamond) should be in a row, and each feature (i.e., carat and clarity) should be a column. To get there, the dataset needs to be reshaped from long to wide. Let’s do that now.",
   "id": "af837dba9bc41dfb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Copy diamonds_char_import in diamonds_char for cleaning\n",
    "diamonds_char = diamonds_char_import.copy()\n",
    "\n",
    "# Reshape the diamonds_char dataset from long to wide\n",
    "\n",
    "\n",
    "diamonds_char.head(4)"
   ],
   "id": "541f82392dd2616a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "That’s better. However, all formatting from the variables is lost. In particular, we need to convert carat to a numeric variable and clarity to an ordered categorical (or factor) variable:",
   "id": "77a466822c85424e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "diamonds_char['carat'] =\n",
    "\n",
    "diamonds_char['clarity'] =\n",
    "\n",
    "diamonds_char.head(4)"
   ],
   "id": "33eb1f30db82dde3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "As a sanity check, let’s inspect the dataset for duplicate observations:\n",
    "\n"
   ],
   "id": "15ecbc3724e14f04"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Check for duplicates in the reshaped dataset\n",
    "duplicates =\n",
    "\n",
    "duplicates.head()"
   ],
   "id": "190a6889de8e8fe5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "OK, no duplicates this time… we are finally ready to join! Remember that we tracked each diamond with a unique identifier. We will use that to reconnect the two datasets.",
   "id": "489bbfac95ea46db"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "diamonds_recon =\n",
    "\n",
    "diamonds_recon.head()"
   ],
   "id": "bde2b4b6ea43c67f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Let’s plot our reconstructed dataset:\n",
    "\n"
   ],
   "id": "ecf1805409c14cd9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sns.relplot(data=diamonds_recon,\n",
    "            x='carat',\n",
    "            y='price',\n",
    "            hue='clarity',\n",
    "            kind='scatter',\n",
    "            alpha=0.3,\n",
    "            palette=sns.color_palette('magma', n_colors=len(diamonds_recon['clarity'].unique()))\n",
    "            )\n",
    "\n",
    "plt.show()"
   ],
   "id": "3f455269549ccb9c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
